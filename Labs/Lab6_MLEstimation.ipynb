{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Likelihood estimation\n",
    "\n",
    "\n",
    "## Objective\n",
    "\n",
    "Experiment with Maximum Likelihood, Maximum A Posteriori and Minimum Mean\n",
    "Squared Error estimation for a basic signal.\n",
    "\n",
    "## Theoretical aspects\n",
    "\n",
    "### ML estimation in gaussian noise\n",
    "\n",
    "### Exercises\n",
    "\n",
    "1. Generate a 300-samples long sinusoidal signal $s_\\Theta = 4 * \\sin(2 \\pi f n)$ with frequency $f = 0.02$,\n",
    "and add over it normal noise with distribution $\\mathcal{N}(0, \\sigma^2 = 2)$.\n",
    "Name the resulting vector `r`. Plot the `r` vector.\n",
    "\n",
    "2. Estimate the frequency $\\hat{f}$ of the signal via Maximum Likelihood estimation,\n",
    "based only on the `r` vector.\n",
    "    * Write the mathematical expression of the Maximum Likelihood estimation in case of Gaussian noise (`Hint:` based on the Euclidean distance)\n",
    "    * Generate 1000 candidate frequencies $f_k$ equally spaced from 0 to 0.5\n",
    "    * Compute the Euclidean distance between `r` and a sine signal with each candidate frequency\n",
    "    * Maximum Likelihood: choose $\\hat{f}_{ML}$ as the candidate frequency which minimizes the Euclidean distance\n",
    "    * Display $\\hat{f}_{ML}$, and plot the resulting sinusoidal along the original\n",
    "    * Try changing the length of the data. How is the estimation accuracy affected?\n",
    "    * Try changing the variance of the noise. How is the estimation accuracy affected?\n",
    "\n",
    "\n",
    "3. Estimate the amplitude $A$ of the signal via Maximum Likelihood Estimation, assuming the frequency is known to be $0.02$, based only on the $r$ vector. \n",
    "    \n",
    "    Use a similar approach as in Exercise 2.\n",
    "    \n",
    "    Try different amplitude values of the signal in Exercise 1, and see if they are estimated correctly.\n",
    "    \n",
    "4. Repeat Exercise 3, but use the Gradient Descent algorithm for estimating $A$, instead of the polling strategy.\n",
    "\n",
    "**Not done**\n",
    "\n",
    "3. TO UPDATE: Suppose that for $f$ we know a *prior distribution* $w(f)$, displayed on the whiteboard.\n",
    "Modify the previous example to implement Bayesian estimation.\n",
    "    * Multiply the computed likelihood function from previous exercise with the prior distribution, for each point.\n",
    "    The result is the *posterior* distribution.\n",
    "    * Maximum A Posteriori: choose $\\hat{f}_{MAP}$ as the value which maximizes the posterior distribution\n",
    "    * Minimum Mean Squared Error: : choose $\\hat{f}_{MMSE}$ as the average value of the posterior distribution\n",
    "    * Display $\\hat{f}_{MAP}$ and $\\hat{f}_{MMSE}$, and plot the resulting sinusoidal signals along the original and the ML one\n",
    "\n",
    "4. *Signal inpainting (recover missing parts of signal)*. Randomly replace 20 samples from `data` with 0, to simulate missing data. \n",
    "Rerun exercise 3 and estimate the original signal. Plot the result(s) against the starting data (with the missing samples) to visualize the result.\n",
    "\n",
    "# Final questions\n",
    "\n",
    "1. TBD\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.16.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
